{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Denoising autoencoder - Fasion MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "InDCMr5tnCrM",
        "uRPhOfJQyxzC",
        "1J3Lvghf2FS8",
        "mhT7tN-cysTF",
        "96Dvyi2tjizp",
        "GK-D4ldQg55e",
        "VNKsRXeZFwUR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InDCMr5tnCrM"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRPhOfJQyxzC"
      },
      "source": [
        "## Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e44TPMq0nQSO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3Lvghf2FS8"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Xmx_9Dlzn2"
      },
      "source": [
        "#@markdown Training parameters\n",
        "#@markdown ---\n",
        "latent_dim = 100 #@param {type:\"slider\", min:50, max:300, step:50}\n",
        "#default: 50\n",
        "NUM_EPOCHS = 30 #@param {type:\"slider\", min:10, max:400, step:10}  \n",
        "#default: 128\n",
        "BATCH_SIZE = 32 #@param {type:\"slider\", min:32, max:512, step:32}\n",
        "INIT_LR = 1e-3 #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Benchmarks\n",
        "#@markdown --\n",
        "OUTPUT_PATH = \"/content/gdrive/MyDrive/Colab Files/Autoencoder/Fashion MNIST/\" #@param {type:\"string\"}\n",
        "SAMPLES_NUM = 8 #@param {type:\"slider\", min:8, max:30, step:1}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhT7tN-cysTF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dXixNIggroG"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Dvyi2tjizp"
      },
      "source": [
        "# Download and Prepare The DataSet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6eX6u23yeDJ"
      },
      "source": [
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
        "trainImages = np.concatenate([trainX, testX])\n",
        "\n",
        "# add a channel dimension to every image in the dataset, then scale\n",
        "# the pixel intensities to the range [0, 1]\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "# sample noise from a random normal distribution centered at 0.5\n",
        "trainNoise = np.random.normal(loc=0.5, scale=0.5, size=trainX.shape)\n",
        "testNoise = np.random.normal(loc=0.5, scale=0.5, size=testX.shape)\n",
        "trainXNoisy = np.clip(trainX + trainNoise, 0, 1)\n",
        "testXNoisy = np.clip(testX + testNoise, 0, 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK-D4ldQg55e"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vabKlpUg8BD"
      },
      "source": [
        "def build_autoencoder(width, height, depth, filters=(32, 64), latentDim=16):\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# define the input to the encoder\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = inputs\n",
        "\n",
        "\t# loop over the number of filters\n",
        "\tfor f in filters:\n",
        "\t\t# apply a CONV => RELU => BN operation\n",
        "\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
        "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\t# flatten the network and then construct our latent vector\n",
        "\tvolumeSize = K.int_shape(x)\n",
        "\tx = Flatten()(x)\n",
        "\tlatent = Dense(latentDim)(x)\n",
        "\n",
        "\t# build the encoder model\n",
        "\tencoder = Model(inputs, latent, name=\"encoder\")\n",
        "\n",
        "\t# start building the decoder model which will accept the\n",
        "\t# output of the encoder as its inputs\n",
        "\tlatentInputs = Input(shape=(latentDim,))\n",
        "\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
        "\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "\n",
        "\t# loop over our number of filters again, but this time in\n",
        "\t# reverse order\n",
        "\tfor f in filters[::-1]:\n",
        "\t\t# apply a CONV_TRANSPOSE => RELU => BN operation\n",
        "\t\tx = Conv2DTranspose(f, (3, 3), strides=2,\n",
        "\t\t\tpadding=\"same\")(x)\n",
        "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\t# apply a single CONV_TRANSPOSE layer used to recover the\n",
        "\t# original depth of the image\n",
        "\tx = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
        "\toutputs = Activation(\"sigmoid\")(x)\n",
        "\n",
        "\t# build the decoder model\n",
        "\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "\n",
        "\t# our autoencoder is the encoder + decoder\n",
        "\tautoencoder = Model(inputs, decoder(encoder(inputs)),\n",
        "\t\tname=\"autoencoder\")\n",
        "\n",
        "\t# return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "\treturn (encoder, decoder, autoencoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNKsRXeZFwUR"
      },
      "source": [
        "# Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wdt3FGQkxVB"
      },
      "source": [
        "# construct our convolutional autoencoder\n",
        "print(\"[INFO] building autoencoder...\")\n",
        "(encoder, decoder, autoencoder) = build_autoencoder(28, 28, 1)\n",
        "opt = Adam(lr=INIT_LR)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "\ttrainXNoisy, trainX,\n",
        "\tvalidation_data=(testXNoisy, testX),\n",
        "\tepochs=NUM_EPOCHS,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# construct a plot that plots and saves the training history\n",
        "N = np.arange(0, NUM_EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(OUTPUT_PATH + \"loss-acc.png\")\n",
        "\n",
        "# use the convolutional autoencoder to make predictions on the\n",
        "# testing images, then initialize our list of output images\n",
        "print(\"[INFO] making predictions...\")\n",
        "decoded = autoencoder.predict(testXNoisy)\n",
        "outputs = None\n",
        "\n",
        "\n",
        "images=[]\n",
        "# loop over our number of output samples\n",
        "for i in range(0, SAMPLES_NUM):\n",
        "\t# grab the original image and reconstructed image\n",
        "\toriginal = (testXNoisy[i] * 255).astype(\"uint8\")\n",
        "\trecon = (decoded[i] * 255).astype(\"uint8\")\n",
        "\n",
        "\t# stack the original and reconstructed image side-by-side\n",
        "\toutput = np.hstack([original, recon])\n",
        "\n",
        "\t# if the outputs array is empty, initialize it as the current\n",
        "\t# side-by-side image display\n",
        "\tif outputs is None:\n",
        "\t\toutputs = output\n",
        "\n",
        "\t# otherwise, vertically stack the outputs\n",
        "\telse:\n",
        "\t\toutputs = np.vstack([outputs, output])\n",
        "\n",
        "\n",
        "p = OUTPUT_PATH + \"output_samples.png\" \n",
        "# save the outputs image to disk\n",
        "cv2.imwrite(p, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}